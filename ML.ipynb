{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff84fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c241614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "# Example: calories.csv should have features + target column \"Calories\"\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b66d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume features like: ['Sex', 'Age', 'Height', 'Weight', 'Duration', 'Heart_Rate', 'Body_Temp']\n",
    "# Drop 'Calories' to get target, also drop 'id' as it's an identifier not a feature.\n",
    "X = data.drop([\"Calories\", \"id\"], axis=1)\n",
    "y = data[\"Calories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17760908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Sex' column in X to numerical values\n",
    "X['Sex'] = X['Sex'].map({'male': 1, 'female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "609d3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Work on a copy of X to ensure preprocessing steps are localized and robust\n",
    "X_to_process = X.copy()\n",
    "\n",
    "# Defensive Step 1: Ensure 'id' column is removed if it exists\n",
    "if 'id' in X_to_process.columns:\n",
    "    X_to_process.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# Defensive Step 2: Ensure 'Sex' column is numeric.\n",
    "# This directly addresses the \"could not convert string to float: 'male'\" error.\n",
    "if 'Sex' in X_to_process.columns and X_to_process['Sex'].dtype == 'object':\n",
    "    X_to_process['Sex'] = X_to_process['Sex'].map({'male': 1, 'female': 0})\n",
    "    # Optionally, convert to int and handle potential NaNs if map could fail for some values\n",
    "    # X_to_process['Sex'] = X_to_process['Sex'].astype(float).fillna(-1).astype(int) # Example NaN handling\n",
    "\n",
    "# Now, X_to_process should have 'Sex' as numeric and no 'id'.\n",
    "# Identify columns to scale from this cleaned DataFrame (all except 'Sex').\n",
    "cols_to_scale = [col for col in X_to_process.columns if col != 'Sex']\n",
    "\n",
    "# Scale the identified columns within X_to_process.\n",
    "# The 'Sex' column (now numeric) will be skipped by this operation.\n",
    "if cols_to_scale:\n",
    "    X_to_process[cols_to_scale] = scaler.fit_transform(X_to_process[cols_to_scale])\n",
    "\n",
    "# Assign the fully processed DataFrame to X_scaled, which is used by subsequent cells.\n",
    "X_scaled = X_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aca748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Heart_Rate</th>\n",
       "      <th>Body_Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.357192</td>\n",
       "      <td>1.115235</td>\n",
       "      <td>0.490201</td>\n",
       "      <td>1.266324</td>\n",
       "      <td>0.583714</td>\n",
       "      <td>1.235772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.487943</td>\n",
       "      <td>-0.912137</td>\n",
       "      <td>-1.083172</td>\n",
       "      <td>-0.888309</td>\n",
       "      <td>-1.109436</td>\n",
       "      <td>-0.431163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.631273</td>\n",
       "      <td>-1.068088</td>\n",
       "      <td>-0.797104</td>\n",
       "      <td>-1.008011</td>\n",
       "      <td>-1.215258</td>\n",
       "      <td>-0.302938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.411555</td>\n",
       "      <td>1.349162</td>\n",
       "      <td>1.062337</td>\n",
       "      <td>1.146622</td>\n",
       "      <td>1.007002</td>\n",
       "      <td>0.851095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.225397</td>\n",
       "      <td>-0.678209</td>\n",
       "      <td>-1.011655</td>\n",
       "      <td>1.146622</td>\n",
       "      <td>0.689536</td>\n",
       "      <td>0.722869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex       Age    Height    Weight  Duration  Heart_Rate  Body_Temp\n",
       "0    1 -0.357192  1.115235  0.490201  1.266324    0.583714   1.235772\n",
       "1    0  1.487943 -0.912137 -1.083172 -0.888309   -1.109436  -0.431163\n",
       "2    0  0.631273 -1.068088 -0.797104 -1.008011   -1.215258  -0.302938\n",
       "3    1 -1.411555  1.349162  1.062337  1.146622    1.007002   0.851095\n",
       "4    0 -0.225397 -0.678209 -1.011655  1.146622    0.689536   0.722869"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6e5b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler configuration saved to scaler_config.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Save scaler parameters and the columns they apply to\n",
    "scaler_params = {\n",
    "    'mean': scaler.mean_.tolist(),\n",
    "    'scale': scaler.scale_.tolist(),\n",
    "    'columns': cols_to_scale # These are the columns the mean_ and scale_ correspond to\n",
    "}\n",
    "with open('scaler_config.json', 'w') as f:\n",
    "    json.dump(scaler_params, f)\n",
    "print(\"Scaler configuration saved to scaler_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d78caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc5f329a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f3b2920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b2cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\priya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Single output for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccf191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 619.4028 - mae: 9.0912 - val_loss: 13.6996 - val_mae: 2.2659\n",
      "Epoch 2/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 619.4028 - mae: 9.0912 - val_loss: 13.6996 - val_mae: 2.2659\n",
      "Epoch 2/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 14.4574 - mae: 2.3090 - val_loss: 13.4546 - val_mae: 2.2381\n",
      "Epoch 3/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 14.4574 - mae: 2.3090 - val_loss: 13.4546 - val_mae: 2.2381\n",
      "Epoch 3/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 14.1773 - mae: 2.2777 - val_loss: 13.1578 - val_mae: 2.1795\n",
      "Epoch 4/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 14.1773 - mae: 2.2777 - val_loss: 13.1578 - val_mae: 2.1795\n",
      "Epoch 4/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 14.0661 - mae: 2.2717 - val_loss: 13.4725 - val_mae: 2.2243\n",
      "Epoch 5/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 14.0661 - mae: 2.2717 - val_loss: 13.4725 - val_mae: 2.2243\n",
      "Epoch 5/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 13.8636 - mae: 2.2638 - val_loss: 13.0851 - val_mae: 2.1812\n",
      "Epoch 6/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 13.8636 - mae: 2.2638 - val_loss: 13.0851 - val_mae: 2.1812\n",
      "Epoch 6/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 13.7111 - mae: 2.2454 - val_loss: 13.5272 - val_mae: 2.2674\n",
      "Epoch 7/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 13.7111 - mae: 2.2454 - val_loss: 13.5272 - val_mae: 2.2674\n",
      "Epoch 7/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 14.3338 - mae: 2.2637 - val_loss: 14.0771 - val_mae: 2.3368\n",
      "Epoch 8/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 14.3338 - mae: 2.2637 - val_loss: 14.0771 - val_mae: 2.3368\n",
      "Epoch 8/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 14.2459 - mae: 2.2461 - val_loss: 12.9023 - val_mae: 2.1873\n",
      "Epoch 9/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 14.2459 - mae: 2.2461 - val_loss: 12.9023 - val_mae: 2.1873\n",
      "Epoch 9/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 13.8921 - mae: 2.2438 - val_loss: 13.0476 - val_mae: 2.1863\n",
      "Epoch 10/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 13.8921 - mae: 2.2438 - val_loss: 13.0476 - val_mae: 2.1863\n",
      "Epoch 10/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 13.4335 - mae: 2.2295 - val_loss: 14.0147 - val_mae: 2.3013\n",
      "Epoch 11/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 13.4335 - mae: 2.2295 - val_loss: 14.0147 - val_mae: 2.3013\n",
      "Epoch 11/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 14.5939 - mae: 2.2425 - val_loss: 13.6386 - val_mae: 2.2374\n",
      "Epoch 12/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 14.5939 - mae: 2.2425 - val_loss: 13.6386 - val_mae: 2.2374\n",
      "Epoch 12/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 13.7025 - mae: 2.2360 - val_loss: 14.0144 - val_mae: 2.3324\n",
      "Epoch 13/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 13.7025 - mae: 2.2360 - val_loss: 14.0144 - val_mae: 2.3324\n",
      "Epoch 13/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 13.4629 - mae: 2.2285 - val_loss: 13.1889 - val_mae: 2.2060\n",
      "Epoch 14/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1ms/step - loss: 13.4629 - mae: 2.2285 - val_loss: 13.1889 - val_mae: 2.2060\n",
      "Epoch 14/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 13.6804 - mae: 2.2337 - val_loss: 13.2888 - val_mae: 2.2200\n",
      "Epoch 15/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 13.6804 - mae: 2.2337 - val_loss: 13.2888 - val_mae: 2.2200\n",
      "Epoch 15/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 13.5314 - mae: 2.2218 - val_loss: 12.9631 - val_mae: 2.1862\n",
      "Epoch 16/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 13.5314 - mae: 2.2218 - val_loss: 12.9631 - val_mae: 2.1862\n",
      "Epoch 16/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 13.4345 - mae: 2.2201 - val_loss: 12.7442 - val_mae: 2.1569\n",
      "Epoch 17/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 13.4345 - mae: 2.2201 - val_loss: 12.7442 - val_mae: 2.1569\n",
      "Epoch 17/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 13.5645 - mae: 2.2209 - val_loss: 12.7356 - val_mae: 2.1487\n",
      "Epoch 18/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 13.5645 - mae: 2.2209 - val_loss: 12.7356 - val_mae: 2.1487\n",
      "Epoch 18/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 13.3542 - mae: 2.2192 - val_loss: 13.2605 - val_mae: 2.2392\n",
      "Epoch 19/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 13.3542 - mae: 2.2192 - val_loss: 13.2605 - val_mae: 2.2392\n",
      "Epoch 19/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 13.6537 - mae: 2.2288 - val_loss: 12.8178 - val_mae: 2.1621\n",
      "Epoch 20/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 13.6537 - mae: 2.2288 - val_loss: 12.8178 - val_mae: 2.1621\n",
      "Epoch 20/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.5535 - mae: 2.2195 - val_loss: 13.2173 - val_mae: 2.2171\n",
      "Epoch 21/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.5535 - mae: 2.2195 - val_loss: 13.2173 - val_mae: 2.2171\n",
      "Epoch 21/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.1647 - mae: 2.2107 - val_loss: 13.4465 - val_mae: 2.2874\n",
      "Epoch 22/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.1647 - mae: 2.2107 - val_loss: 13.4465 - val_mae: 2.2874\n",
      "Epoch 22/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.4182 - mae: 2.2198 - val_loss: 12.6361 - val_mae: 2.1279\n",
      "Epoch 23/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.4182 - mae: 2.2198 - val_loss: 12.6361 - val_mae: 2.1279\n",
      "Epoch 23/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2439 - mae: 2.2175 - val_loss: 12.7254 - val_mae: 2.1557\n",
      "Epoch 24/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2439 - mae: 2.2175 - val_loss: 12.7254 - val_mae: 2.1557\n",
      "Epoch 24/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.3921 - mae: 2.2134 - val_loss: 12.7216 - val_mae: 2.1554\n",
      "Epoch 25/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.3921 - mae: 2.2134 - val_loss: 12.7216 - val_mae: 2.1554\n",
      "Epoch 25/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.1470 - mae: 2.2076 - val_loss: 12.9703 - val_mae: 2.1872\n",
      "Epoch 26/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.1470 - mae: 2.2076 - val_loss: 12.9703 - val_mae: 2.1872\n",
      "Epoch 26/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.4059 - mae: 2.2191 - val_loss: 12.9273 - val_mae: 2.1722\n",
      "Epoch 27/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.4059 - mae: 2.2191 - val_loss: 12.9273 - val_mae: 2.1722\n",
      "Epoch 27/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.3449 - mae: 2.2123 - val_loss: 12.8258 - val_mae: 2.1764\n",
      "Epoch 28/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.3449 - mae: 2.2123 - val_loss: 12.8258 - val_mae: 2.1764\n",
      "Epoch 28/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.0399 - mae: 2.2001 - val_loss: 13.5585 - val_mae: 2.2711\n",
      "Epoch 29/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.0399 - mae: 2.2001 - val_loss: 13.5585 - val_mae: 2.2711\n",
      "Epoch 29/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.0486 - mae: 2.2101 - val_loss: 12.7409 - val_mae: 2.1963\n",
      "Epoch 30/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.0486 - mae: 2.2101 - val_loss: 12.7409 - val_mae: 2.1963\n",
      "Epoch 30/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 12.9848 - mae: 2.2037 - val_loss: 12.9353 - val_mae: 2.1785\n",
      "Epoch 31/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 12.9848 - mae: 2.2037 - val_loss: 12.9353 - val_mae: 2.1785\n",
      "Epoch 31/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.3500 - mae: 2.2074 - val_loss: 12.9441 - val_mae: 2.1776\n",
      "Epoch 32/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.3500 - mae: 2.2074 - val_loss: 12.9441 - val_mae: 2.1776\n",
      "Epoch 32/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 12.9134 - mae: 2.1999 - val_loss: 13.1381 - val_mae: 2.2324\n",
      "Epoch 33/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 12.9134 - mae: 2.1999 - val_loss: 13.1381 - val_mae: 2.2324\n",
      "Epoch 33/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.3813 - mae: 2.2107 - val_loss: 12.9841 - val_mae: 2.2052\n",
      "Epoch 34/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.3813 - mae: 2.2107 - val_loss: 12.9841 - val_mae: 2.2052\n",
      "Epoch 34/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.7471 - mae: 2.2191 - val_loss: 12.5892 - val_mae: 2.1543\n",
      "Epoch 35/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.7471 - mae: 2.2191 - val_loss: 12.5892 - val_mae: 2.1543\n",
      "Epoch 35/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2560 - mae: 2.2051 - val_loss: 12.5467 - val_mae: 2.1476\n",
      "Epoch 36/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2560 - mae: 2.2051 - val_loss: 12.5467 - val_mae: 2.1476\n",
      "Epoch 36/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2974 - mae: 2.1993 - val_loss: 12.6755 - val_mae: 2.1525\n",
      "Epoch 37/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2974 - mae: 2.1993 - val_loss: 12.6755 - val_mae: 2.1525\n",
      "Epoch 37/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2396 - mae: 2.1983 - val_loss: 13.3594 - val_mae: 2.2316\n",
      "Epoch 38/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.2396 - mae: 2.1983 - val_loss: 13.3594 - val_mae: 2.2316\n",
      "Epoch 38/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.0655 - mae: 2.1941 - val_loss: 12.8357 - val_mae: 2.1857\n",
      "Epoch 39/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.0655 - mae: 2.1941 - val_loss: 12.8357 - val_mae: 2.1857\n",
      "Epoch 39/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.1386 - mae: 2.1966 - val_loss: 12.9412 - val_mae: 2.2332\n",
      "Epoch 40/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 13.1386 - mae: 2.1966 - val_loss: 12.9412 - val_mae: 2.2332\n",
      "Epoch 40/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 12.8554 - mae: 2.1954 - val_loss: 12.8028 - val_mae: 2.1854\n",
      "Epoch 41/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 12.8554 - mae: 2.1954 - val_loss: 12.8028 - val_mae: 2.1854\n",
      "Epoch 41/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9197 - mae: 2.1974 - val_loss: 13.2700 - val_mae: 2.2823\n",
      "Epoch 42/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9197 - mae: 2.1974 - val_loss: 13.2700 - val_mae: 2.2823\n",
      "Epoch 42/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.0426 - mae: 2.1955 - val_loss: 12.6807 - val_mae: 2.1659\n",
      "Epoch 43/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.0426 - mae: 2.1955 - val_loss: 12.6807 - val_mae: 2.1659\n",
      "Epoch 43/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9079 - mae: 2.1875 - val_loss: 12.6520 - val_mae: 2.1537\n",
      "Epoch 44/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9079 - mae: 2.1875 - val_loss: 12.6520 - val_mae: 2.1537\n",
      "Epoch 44/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.0146 - mae: 2.1971 - val_loss: 13.8410 - val_mae: 2.2690\n",
      "Epoch 45/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.0146 - mae: 2.1971 - val_loss: 13.8410 - val_mae: 2.2690\n",
      "Epoch 45/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.1008 - mae: 2.1897 - val_loss: 12.6034 - val_mae: 2.1551\n",
      "Epoch 46/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.1008 - mae: 2.1897 - val_loss: 12.6034 - val_mae: 2.1551\n",
      "Epoch 46/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9508 - mae: 2.1928 - val_loss: 12.8800 - val_mae: 2.1895\n",
      "Epoch 47/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9508 - mae: 2.1928 - val_loss: 12.8800 - val_mae: 2.1895\n",
      "Epoch 47/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2026 - mae: 2.1979 - val_loss: 12.4177 - val_mae: 2.1293\n",
      "Epoch 48/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2026 - mae: 2.1979 - val_loss: 12.4177 - val_mae: 2.1293\n",
      "Epoch 48/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.1670 - mae: 2.1923 - val_loss: 12.5133 - val_mae: 2.1657\n",
      "Epoch 49/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.1670 - mae: 2.1923 - val_loss: 12.5133 - val_mae: 2.1657\n",
      "Epoch 49/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7057 - mae: 2.1866 - val_loss: 12.6092 - val_mae: 2.1615\n",
      "Epoch 50/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7057 - mae: 2.1866 - val_loss: 12.6092 - val_mae: 2.1615\n",
      "Epoch 50/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2293 - mae: 2.1968 - val_loss: 12.5429 - val_mae: 2.1404\n",
      "Epoch 51/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2293 - mae: 2.1968 - val_loss: 12.5429 - val_mae: 2.1404\n",
      "Epoch 51/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7052 - mae: 2.1821 - val_loss: 12.6797 - val_mae: 2.1510\n",
      "Epoch 52/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7052 - mae: 2.1821 - val_loss: 12.6797 - val_mae: 2.1510\n",
      "Epoch 52/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2088 - mae: 2.1859 - val_loss: 12.6060 - val_mae: 2.1529\n",
      "Epoch 53/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2088 - mae: 2.1859 - val_loss: 12.6060 - val_mae: 2.1529\n",
      "Epoch 53/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8451 - mae: 2.1905 - val_loss: 12.5981 - val_mae: 2.1565\n",
      "Epoch 54/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8451 - mae: 2.1905 - val_loss: 12.5981 - val_mae: 2.1565\n",
      "Epoch 54/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.0265 - mae: 2.1837 - val_loss: 12.5374 - val_mae: 2.1451\n",
      "Epoch 55/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.0265 - mae: 2.1837 - val_loss: 12.5374 - val_mae: 2.1451\n",
      "Epoch 55/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6981 - mae: 2.1831 - val_loss: 12.9933 - val_mae: 2.2134\n",
      "Epoch 56/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6981 - mae: 2.1831 - val_loss: 12.9933 - val_mae: 2.2134\n",
      "Epoch 56/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 12.9313 - mae: 2.1896 - val_loss: 12.8049 - val_mae: 2.2002\n",
      "Epoch 57/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 12.9313 - mae: 2.1896 - val_loss: 12.8049 - val_mae: 2.2002\n",
      "Epoch 57/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7686 - mae: 2.1778 - val_loss: 12.5842 - val_mae: 2.1597\n",
      "Epoch 58/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7686 - mae: 2.1778 - val_loss: 12.5842 - val_mae: 2.1597\n",
      "Epoch 58/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 13.2079 - mae: 2.1902 - val_loss: 13.0532 - val_mae: 2.2229\n",
      "Epoch 59/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 13.2079 - mae: 2.1902 - val_loss: 13.0532 - val_mae: 2.2229\n",
      "Epoch 59/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8204 - mae: 2.1880 - val_loss: 12.6965 - val_mae: 2.1697\n",
      "Epoch 60/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8204 - mae: 2.1880 - val_loss: 12.6965 - val_mae: 2.1697\n",
      "Epoch 60/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8459 - mae: 2.1759 - val_loss: 12.7483 - val_mae: 2.1620\n",
      "Epoch 61/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8459 - mae: 2.1759 - val_loss: 12.7483 - val_mae: 2.1620\n",
      "Epoch 61/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7526 - mae: 2.1782 - val_loss: 12.4146 - val_mae: 2.1202\n",
      "Epoch 62/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7526 - mae: 2.1782 - val_loss: 12.4146 - val_mae: 2.1202\n",
      "Epoch 62/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8891 - mae: 2.1811 - val_loss: 12.9707 - val_mae: 2.1940\n",
      "Epoch 63/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8891 - mae: 2.1811 - val_loss: 12.9707 - val_mae: 2.1940\n",
      "Epoch 63/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7325 - mae: 2.1770 - val_loss: 12.6676 - val_mae: 2.1827\n",
      "Epoch 64/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7325 - mae: 2.1770 - val_loss: 12.6676 - val_mae: 2.1827\n",
      "Epoch 64/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8110 - mae: 2.1765 - val_loss: 13.7130 - val_mae: 2.3049\n",
      "Epoch 65/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8110 - mae: 2.1765 - val_loss: 13.7130 - val_mae: 2.3049\n",
      "Epoch 65/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7899 - mae: 2.1798 - val_loss: 12.8807 - val_mae: 2.2274\n",
      "Epoch 66/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7899 - mae: 2.1798 - val_loss: 12.8807 - val_mae: 2.2274\n",
      "Epoch 66/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8515 - mae: 2.1776 - val_loss: 12.8244 - val_mae: 2.2041\n",
      "Epoch 67/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8515 - mae: 2.1776 - val_loss: 12.8244 - val_mae: 2.2041\n",
      "Epoch 67/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8401 - mae: 2.1763 - val_loss: 12.5570 - val_mae: 2.1707\n",
      "Epoch 68/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.8401 - mae: 2.1763 - val_loss: 12.5570 - val_mae: 2.1707\n",
      "Epoch 68/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.1515 - mae: 2.1864 - val_loss: 12.9251 - val_mae: 2.2003\n",
      "Epoch 69/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.1515 - mae: 2.1864 - val_loss: 12.9251 - val_mae: 2.2003\n",
      "Epoch 69/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2574 - mae: 2.1783 - val_loss: 12.7728 - val_mae: 2.1777\n",
      "Epoch 70/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 13.2574 - mae: 2.1783 - val_loss: 12.7728 - val_mae: 2.1777\n",
      "Epoch 70/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9801 - mae: 2.1820 - val_loss: 12.4990 - val_mae: 2.1195\n",
      "Epoch 71/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.9801 - mae: 2.1820 - val_loss: 12.4990 - val_mae: 2.1195\n",
      "Epoch 71/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7545 - mae: 2.1663 - val_loss: 12.7557 - val_mae: 2.1653\n",
      "Epoch 72/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 12.7545 - mae: 2.1663 - val_loss: 12.7557 - val_mae: 2.1653\n",
      "Epoch 72/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.9138 - mae: 2.1754 - val_loss: 13.2945 - val_mae: 2.2410\n",
      "Epoch 73/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.9138 - mae: 2.1754 - val_loss: 13.2945 - val_mae: 2.2410\n",
      "Epoch 73/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.8815 - mae: 2.1749 - val_loss: 13.1744 - val_mae: 2.2325\n",
      "Epoch 74/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.8815 - mae: 2.1749 - val_loss: 13.1744 - val_mae: 2.2325\n",
      "Epoch 74/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 13.1213 - mae: 2.1854 - val_loss: 12.5459 - val_mae: 2.1292\n",
      "Epoch 75/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 13.1213 - mae: 2.1854 - val_loss: 12.5459 - val_mae: 2.1292\n",
      "Epoch 75/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.5721 - mae: 2.1679 - val_loss: 12.6082 - val_mae: 2.1415\n",
      "Epoch 76/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.5721 - mae: 2.1679 - val_loss: 12.6082 - val_mae: 2.1415\n",
      "Epoch 76/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.7323 - mae: 2.1770 - val_loss: 12.9082 - val_mae: 2.1641\n",
      "Epoch 77/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.7323 - mae: 2.1770 - val_loss: 12.9082 - val_mae: 2.1641\n",
      "Epoch 77/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.9177 - mae: 2.1750 - val_loss: 12.7927 - val_mae: 2.1772\n",
      "Epoch 78/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.9177 - mae: 2.1750 - val_loss: 12.7927 - val_mae: 2.1772\n",
      "Epoch 78/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 13.0113 - mae: 2.1841 - val_loss: 12.8326 - val_mae: 2.1622\n",
      "Epoch 79/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 13.0113 - mae: 2.1841 - val_loss: 12.8326 - val_mae: 2.1622\n",
      "Epoch 79/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.7862 - mae: 2.1715 - val_loss: 12.6797 - val_mae: 2.1606\n",
      "Epoch 80/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.7862 - mae: 2.1715 - val_loss: 12.6797 - val_mae: 2.1606\n",
      "Epoch 80/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6534 - mae: 2.1737 - val_loss: 12.7016 - val_mae: 2.1493\n",
      "Epoch 81/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6534 - mae: 2.1737 - val_loss: 12.7016 - val_mae: 2.1493\n",
      "Epoch 81/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.7770 - mae: 2.1642 - val_loss: 12.5966 - val_mae: 2.1317\n",
      "Epoch 82/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.7770 - mae: 2.1642 - val_loss: 12.5966 - val_mae: 2.1317\n",
      "Epoch 82/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6399 - mae: 2.1707 - val_loss: 12.9787 - val_mae: 2.1876\n",
      "Epoch 83/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6399 - mae: 2.1707 - val_loss: 12.9787 - val_mae: 2.1876\n",
      "Epoch 83/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.5488 - mae: 2.1630 - val_loss: 12.5952 - val_mae: 2.1461\n",
      "Epoch 84/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.5488 - mae: 2.1630 - val_loss: 12.5952 - val_mae: 2.1461\n",
      "Epoch 84/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6388 - mae: 2.1630 - val_loss: 12.7254 - val_mae: 2.1602\n",
      "Epoch 85/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6388 - mae: 2.1630 - val_loss: 12.7254 - val_mae: 2.1602\n",
      "Epoch 85/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.9879 - mae: 2.1659 - val_loss: 12.8737 - val_mae: 2.1621\n",
      "Epoch 86/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.9879 - mae: 2.1659 - val_loss: 12.8737 - val_mae: 2.1621\n",
      "Epoch 86/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6509 - mae: 2.1696 - val_loss: 12.5706 - val_mae: 2.1204\n",
      "Epoch 87/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6509 - mae: 2.1696 - val_loss: 12.5706 - val_mae: 2.1204\n",
      "Epoch 87/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7675 - mae: 2.1740 - val_loss: 12.6379 - val_mae: 2.1513\n",
      "Epoch 88/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7675 - mae: 2.1740 - val_loss: 12.6379 - val_mae: 2.1513\n",
      "Epoch 88/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7665 - mae: 2.1731 - val_loss: 13.2093 - val_mae: 2.2001\n",
      "Epoch 89/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7665 - mae: 2.1731 - val_loss: 13.2093 - val_mae: 2.2001\n",
      "Epoch 89/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 13.0184 - mae: 2.1763 - val_loss: 12.7569 - val_mae: 2.1363\n",
      "Epoch 90/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 13.0184 - mae: 2.1763 - val_loss: 12.7569 - val_mae: 2.1363\n",
      "Epoch 90/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6041 - mae: 2.1653 - val_loss: 12.6933 - val_mae: 2.1297\n",
      "Epoch 91/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6041 - mae: 2.1653 - val_loss: 12.6933 - val_mae: 2.1297\n",
      "Epoch 91/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.5917 - mae: 2.1641 - val_loss: 13.0293 - val_mae: 2.1487\n",
      "Epoch 92/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.5917 - mae: 2.1641 - val_loss: 13.0293 - val_mae: 2.1487\n",
      "Epoch 92/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8105 - mae: 2.1709 - val_loss: 12.8155 - val_mae: 2.1600\n",
      "Epoch 93/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8105 - mae: 2.1709 - val_loss: 12.8155 - val_mae: 2.1600\n",
      "Epoch 93/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.6059 - mae: 2.1693 - val_loss: 12.4462 - val_mae: 2.1126\n",
      "Epoch 94/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.6059 - mae: 2.1693 - val_loss: 12.4462 - val_mae: 2.1126\n",
      "Epoch 94/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.5664 - mae: 2.1552 - val_loss: 13.0939 - val_mae: 2.1813\n",
      "Epoch 95/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.5664 - mae: 2.1552 - val_loss: 13.0939 - val_mae: 2.1813\n",
      "Epoch 95/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.8582 - mae: 2.1681 - val_loss: 13.3122 - val_mae: 2.2136\n",
      "Epoch 96/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 12.8582 - mae: 2.1681 - val_loss: 13.3122 - val_mae: 2.2136\n",
      "Epoch 96/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7293 - mae: 2.1742 - val_loss: 12.4158 - val_mae: 2.1225\n",
      "Epoch 97/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7293 - mae: 2.1742 - val_loss: 12.4158 - val_mae: 2.1225\n",
      "Epoch 97/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.5526 - mae: 2.1570 - val_loss: 13.3060 - val_mae: 2.2362\n",
      "Epoch 98/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.5526 - mae: 2.1570 - val_loss: 13.3060 - val_mae: 2.2362\n",
      "Epoch 98/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6426 - mae: 2.1641 - val_loss: 12.7230 - val_mae: 2.1368\n",
      "Epoch 99/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.6426 - mae: 2.1641 - val_loss: 12.7230 - val_mae: 2.1368\n",
      "Epoch 99/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8781 - mae: 2.1695 - val_loss: 12.6838 - val_mae: 2.1306\n",
      "Epoch 100/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.8781 - mae: 2.1695 - val_loss: 12.6838 - val_mae: 2.1306\n",
      "Epoch 100/100\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7570 - mae: 2.1596 - val_loss: 12.6502 - val_mae: 2.1462\n",
      "\u001b[1m15000/15000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 12.7570 - mae: 2.1596 - val_loss: 12.6502 - val_mae: 2.1462\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'Sex' column in X_train and X_test is numeric - THIS IS NOW HANDLED IN CELL 866aa306\n",
    "# X_train['Sex'] = X_train['Sex'].map({'male': 1, 'female': 0}) # This line is removed\n",
    "# X_test['Sex'] = X_test['Sex'].map({'male': 1, 'female': 0}) # This line is removed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b297c528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4688/4688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 817us/step - loss: 13.3623 - mae: 2.1620\n",
      "Test MAE: 2.1591124534606934\n",
      "\u001b[1m4688/4688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 817us/step - loss: 13.3623 - mae: 2.1620\n",
      "Test MAE: 2.1591124534606934\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66c29681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Sample Predictions: [197.12555   64.187584  40.519905 103.34368   54.717712]\n",
      "Sample Predictions: [197.12555   64.187584  40.519905 103.34368   54.717712]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "predictions = model.predict(X_test[:5])\n",
    "print(\"Sample Predictions:\", predictions.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c2defc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=h5\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"calories_model.h5\", save_format='h5')  # Save the model for later use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
